{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAFy_z3fQ6S8"
   },
   "source": [
    "# Industrial AI: BHGEâ€™s Physics-based Probabilistic, Deep Learning using TensorFlow Probability\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1De0-Q95i3LuUXa4Zr1KUGTMp59_pEdQq\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"  />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Ported to [Tensorflow Probability](https://www.tensorflow.org/probability/) by Arun Subramaniyan and Fabio Nonato, with help from Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), Bryan Seybold, Mike Shwe ([`@mikeshwe`](https://twitter.com/mikeshwe)), Josh Dillon, and the rest of the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRd3o6MIRHmI"
   },
   "source": [
    "### Dependencies & Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FCtBXX0mQxRO",
    "outputId": "e4b9ad34-9a53-4fb4-b809-e72377b1b078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Up-to-date, stable  TFP version installed\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#@title Tensorflow Probability Installation (make sure to run this cell)  { display-mode: \"form\" }\n",
    "TFP_Installation = \"Stable TFP\" #@param [\"Most Recent TFP\", \"Stable TFP\", \"Stable TFP-GPU\", \"Most Recent TFP-GPU\", \"TFP Already Installed\"]\n",
    "\n",
    "if TFP_Installation == \"Most Recent TFP\":\n",
    "    !pip3 install -q tfp-nightly\n",
    "    print(\"Most recent TFP version installed\")\n",
    "elif TFP_Installation == \"Stable TFP\":\n",
    "    !pip3 install -q --upgrade tensorflow-probability\n",
    "    print(\"Up-to-date, stable  TFP version installed\")\n",
    "elif TFP_Installation == \"Stable TFP-GPU\":\n",
    "    !pip3 install -q --upgrade tensorflow-probability-gpu\n",
    "    print(\"Up-to-date, stable TFP-GPU version installed\")\n",
    "    print(\"(make sure GPU is properly configured)\")\n",
    "elif TFP_Installation == \"Most Recent TFP-GPU\":\n",
    "    !pip3 install -q tfp-nightly-gpu\n",
    "    print(\"Most recent TFP-GPU version installed\")\n",
    "    print(\"(make sure GPU is properly configured)\")\n",
    "elif TFP_Installation == \"TFP Already Installed\":\n",
    "    print(\"TFP already instaled in this environment\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"Installation Error: Please select a viable TFP installation option.\")\n",
    "!pip3 install -q corner seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ll9SIJZtRTEk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#@title Imports and Global Variables (make sure to run this cell)  { display-mode: \"form\" }\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
    "import warnings\n",
    "warnings.filterwarnings(warning_status)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
    "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import matplotlib \n",
    "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "import pandas as pd\n",
    "import matplotlib.axes as axes;\n",
    "matplotlib.rc('xtick', labelsize=20)     \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "font = {'family' : 'Dejavu Sans','size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
    "%config InlineBackend.figure_format = notebook_screen_res\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "              \n",
    "import tensorflow as tf\n",
    "from tensorflow_probability.python.mcmc import util as mcmc_util\n",
    "tfe = tf.contrib.eager\n",
    "\n",
    "# Eager Execution\n",
    "use_tf_eager = False #@param {type:\"boolean\"}\n",
    "\n",
    "# Use try/except so we can easily re-execute the whole notebook.\n",
    "if use_tf_eager:\n",
    "  try:\n",
    "    tf.enable_eager_execution()\n",
    "  except:\n",
    "    reset_session()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "def default_session_options(enable_gpu_ram_resizing=True,\n",
    "                            enable_xla=False):\n",
    "  \"\"\"Creates default options for Graph-mode session.\"\"\"\n",
    "  config = tf.ConfigProto()\n",
    "  config.log_device_placement = True\n",
    "  if enable_gpu_ram_resizing:\n",
    "    # `allow_growth=True` makes it possible to connect multiple\n",
    "    # colabs to your GPU. Otherwise the colab malloc's all GPU ram.\n",
    "    config.gpu_options.allow_growth = True\n",
    "  if enable_xla:\n",
    "    # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
    "    config.graph_options.optimizer_options.global_jit_level = (\n",
    "        tf.OptimizerOptions.ON_1)\n",
    "  return config\n",
    "\n",
    "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
    "    \"\"\"\n",
    "    Allowing the notebook to make use of GPUs if they're available.\n",
    "    \n",
    "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
    "    algebra that optimizes TensorFlow computations.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.log_device_placement = True\n",
    "    if enable_gpu_ram_resizing:\n",
    "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
    "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
    "        config.gpu_options.allow_growth = True\n",
    "    if enable_xla:\n",
    "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
    "        config.graph_options.optimizer_options.global_jit_level = (\n",
    "            tf.OptimizerOptions.ON_1)\n",
    "    return config\n",
    "\n",
    "def reset_session(options=None):\n",
    "  \"\"\"Creates a new global, interactive session in Graph-mode.\"\"\"\n",
    "  if tf.executing_eagerly():\n",
    "    return\n",
    "  global sess\n",
    "  try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "  except:\n",
    "    pass\n",
    "  if options is None:\n",
    "    options = default_session_options()\n",
    "  sess = tf.InteractiveSession(config=options)\n",
    "\n",
    "\n",
    "def evaluate(tensors):\n",
    "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
    "    Args:\n",
    "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
    "        `namedtuple` or combinations thereof.\n",
    "\n",
    "    Returns:\n",
    "        ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
    "          `EagerTensor`s replaced by Numpy `ndarray`s.\n",
    "    \"\"\"\n",
    "    if tf.executing_eagerly():\n",
    "        return tf.contrib.framework.nest.pack_sequence_as(\n",
    "            tensors,\n",
    "            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
    "             for t in tf.contrib.framework.nest.flatten(tensors)])\n",
    "    return sess.run(tensors)\n",
    "  \n",
    "def reset_sess(config=None):\n",
    "    \"\"\"\n",
    "    Convenience function to create the TF graph & session or reset them.\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = session_options()\n",
    "    global sess\n",
    "    tf.reset_default_graph()\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "reset_sess()\n",
    "\n",
    "\n",
    "class _TFColor(object):\n",
    "  \"\"\"Enum of colors used in TF docs.\"\"\"\n",
    "  red = '#F15854'\n",
    "  blue = '#5DA5DA'\n",
    "  orange = '#FAA43A'\n",
    "  green = '#60BD68'\n",
    "  pink = '#F17CB0'\n",
    "  brown = '#B2912F'\n",
    "  purple = '#B276B2'\n",
    "  yellow = '#DECF3F'\n",
    "  gray = '#4D4D4D'\n",
    "  def __getitem__(self, i):\n",
    "    return [\n",
    "        self.red,\n",
    "        self.orange,\n",
    "        self.green,\n",
    "        self.blue,\n",
    "        self.pink,\n",
    "        self.brown,\n",
    "        self.purple,\n",
    "        self.yellow,\n",
    "        self.gray,\n",
    "    ][i % 9]\n",
    "TFColor = _TFColor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aAdCS0rAVrI9"
   },
   "source": [
    "Predicting the life of a component that is prone to cracking is an age-old problem that has been studied ad-nauseam by the [fracture mechanics community](https://www.google.com/search?tbm=bks&q=fracture+mechanics).  [Crack propagation models](https://en.wikipedia.org/wiki/Fracture_mechanics) are at the core of Prognostics and Health Management (PHM) solutions for engineering systems and the aptly titled book [Prognostics and Health Management of Engineering Systems: An Introduction](https://books.google.com/books?id=pv9RDQAAQBAJ&lpg=PR3&dq=prognostics%20and%20health%20management%20of%20engineering%20systems&pg=PR3#v=onepage&q=prognostics%20and%20health%20management%20of%20engineering%20systems&f=false) provides a great example of how real world data can be used to calibrate engineering models. With the example below, we would like to motivate the use of \"Hybrid models\" that combine probabilistic learning techniques and engineering domain models. \n",
    "\n",
    "The phenomenon of fatigue crack propagation can be modeled with the Paris law. Paris law relates the rate of crack growth $\\left(da/dN\\right)$ to the stress intensity factor  $\\left(\\Delta K = \\Delta\\sigma\\sqrt{\\pi a}\\right)$ through the equation below:\n",
    "\n",
    "$\\frac{da}{dN}=C(\\Delta\\sigma\\sqrt{\\pi a})^m$\n",
    "\n",
    "Where $a$ is the crack length, $N$ is the number of loading cycles, $\\sigma$ is the stress, and $C, m$ are material properties.\n",
    "\n",
    "Integrating the Paris law for a specific geometry and loading configuration, we arrive at the analytical formulation for the size of a crack as a function of the loading cycle as shown below:\n",
    "\n",
    "$a(N) = \\left[ N  C \\left(1-\\frac{m}{2}\\right) \\left(\\Delta\\sigma\\sqrt{\\pi}\\right)^m + a_0^{1-\\frac{m}{2}}\\right]^\\frac{2}{2-m}$\n",
    "\n",
    "where $a_0$ is the initial crack length. \n",
    " \n",
    "The parameters $C$ and $m$ need to be calibrated for each application with crack length $(a)$ vs loading cycles $(N)$ data. Such data is usually obtained during maintenance and inspections of engineering systems. In this example, we will use the sample dataset from  the [PHM book by Kim, An and Choi](https://books.google.com/books?id=pv9RDQAAQBAJ&lpg=PR3&dq=prognostics%20and%20health%20management%20of%20engineering%20systems&pg=PR3#v=onepage&q=prognostics%20and%20health%20management%20of%20engineering%20systems&f=false) . \n",
    " \n",
    "We will demonstrate a probabilistic calibration of $C$ and $m$ using Tensorflow Probability.\n",
    "\n",
    "At BHGE Digital we leverage our [Depend-on-Docker](https://github.com/bhgedigital/depend-on-docker) project for automating analytics development. A sample of such automation is available [here](https://github.com/bhgedigital/bayesian_calibration), with the complete code of the example below. \n",
    "\n",
    "With the right automation for developing and deploying analytics in place,  we start by importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "5JP0EwM2Xt48",
    "outputId": "cba426d2-f174-4fc4-d4be-c6c48cae9a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tensorflow_probability.python.mcmc import util as mcmc_util\n",
    "import time\n",
    "import math \n",
    "\n",
    "import matplotlib     \n",
    "matplotlib.rc('xtick', labelsize=20)     \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "\n",
    "font = {'family' : 'Dejavu Sans','size'   : 20}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FH7VQ4RVxvH"
   },
   "source": [
    "### Setting up the data\n",
    "\n",
    "Setting up the data for the calibration comes next. Here we leverage the dataset provided in the Table 4.2 of the [PHM book by Kim, An and Choi](https://books.google.com/books?id=pv9RDQAAQBAJ&lpg=PR3&dq=prognostics%20and%20health%20management%20of%20engineering%20systems&pg=PR3#v=onepage&q=prognostics%20and%20health%20management%20of%20engineering%20systems&f=false):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAkSfpcYfDro"
   },
   "outputs": [],
   "source": [
    "# true values of the parameters\n",
    "t = tf.range(0.,1600., 100) #cycles\n",
    "y = tf.constant([0.0100,0.0109,0.0101,0.0107,0.0110,0.0123,0.0099,0.0113, \n",
    "   0.0132,0.0138,0.0148,0.0156,0.0155,0.0141,0.0169,0.0168]) # measured crack size data\n",
    "# The evaluate() function, defined at the top of this notebook, runs `sess.run()` \n",
    "# in graph mode and allows code to be executed eagerly when Eager mode is enabled\n",
    "[ t_, y_ ] = evaluate([t, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYVCaMNQjBuy"
   },
   "source": [
    "### Priors\n",
    "\n",
    "For Bayesian calibration, we need to define the prior distributions for the calibration variables. In a real application, these priors can be informed by a subject matter expert. For this example, we will assume that both $C$ and $m$ are Gaussian and independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STVPdLVBf_dh"
   },
   "outputs": [],
   "source": [
    "prio_par_logC = [-23., 1.1] # [location, scale] for Normal Prior\n",
    "prio_par_m = [4., 0.2] # [location, scale] for Normal Prior\n",
    "rv_logC = tfd.Normal(loc=0., scale=1., name='logC_norm')\n",
    "rv_m = tfd.Normal(loc=0., scale=1., name='m_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9BUnBm6V8Sv"
   },
   "source": [
    "### Log-prob function\n",
    "\n",
    "We have defined external parameters and standard Normal distribution for both variables, just to sample from a normalized space. Therefore, we will need to de-normalize both random variables when computing the crack model.\n",
    "\n",
    "Now we define the joint log probability for the random variables being calibrated and the associated crack model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_T_cyPQsTxqU"
   },
   "outputs": [],
   "source": [
    "def joint_log_prob(cycles, observations, y0, logC_norm, m_norm):\n",
    "    # Joint logProbability function for both random variables and observations.\n",
    "    # Some constants\n",
    "    dsig = 75.\n",
    "    B = tf.constant(dsig * np.pi**0.5, tf.float32)\n",
    "    # Computing m and logC on original space\n",
    "    logC = logC_norm * prio_par_logC[1]**0.5+ prio_par_logC[0] # \n",
    "    m = m_norm * prio_par_m[1]**0.5 + prio_par_m[0]\n",
    "\n",
    "    # Crack Propagation model\n",
    "    crack_model =(cycles * tf.exp(logC) * (1 - m / 2.) * B**m + y0**(1-m / 2.))**(2. / (2. - m))\n",
    "    y_model = observations - crack_model\n",
    "\n",
    "\n",
    "    # Defining child model random variable\n",
    "    rv_model = tfd.Independent(\n",
    "        tfd.Normal(loc=tf.zeros(observations.shape), scale=0.001),\n",
    "       reinterpreted_batch_ndims=1, name = 'model')\n",
    "    # Sum of logProbabilities\n",
    "    return rv_logC.log_prob(logC_norm) + rv_m.log_prob(m_norm) + rv_model.log_prob(y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB-p5Sd4WAIb"
   },
   "source": [
    "### Sampler\n",
    "\n",
    "Finally, it is time to set up the sampler and run a Tensorflow session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "H_ainmVNT8gW",
    "outputId": "3dd8a7d0-2cdc-4425-d6b0-8ec91be293aa"
   },
   "outputs": [],
   "source": [
    "# This cell can take 12 minutes to run in Graph mode\n",
    "# Number of samples and burnin for the MCMC sampler\n",
    "samples = 10000\n",
    "burnin = 10000\n",
    "\n",
    "# Initial state for the HMC\n",
    "initial_state = [0., 0.]\n",
    "# Converting the data into tensors\n",
    "cycles = tf.convert_to_tensor(t_,tf.float32)\n",
    "observations = tf.convert_to_tensor(y_,tf.float32)\n",
    "y0 = tf.convert_to_tensor(y_[0], tf.float32)\n",
    "# Setting up a target posterior for our joint logprobability\n",
    "unormalized_target_posterior= lambda *args: joint_log_prob(cycles, observations, y0, *args)\n",
    "# And finally setting up the mcmc sampler\n",
    "[logC_samples, m_samples], kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results= samples, \n",
    "    num_burnin_steps= burnin,\n",
    "    current_state=initial_state,\n",
    "    kernel= tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=unormalized_target_posterior,\n",
    "        step_size = 0.045, \n",
    "        num_leapfrog_steps=6))\n",
    "\n",
    "\n",
    "# Tracking the acceptance rate for the sampled chain\n",
    "acceptance_rate = tf.reduce_mean(tf.to_float(kernel_results.is_accepted))\n",
    "\n",
    "# Actually running the sampler\n",
    "# The evaluate() function, defined at the top of this notebook, runs `sess.run()` \n",
    "# in graph mode and allows code to be executed eagerly when Eager mode is enabled\n",
    "[logC_samples_, m_samples_, acceptance_rate_] = evaluate([\n",
    "    logC_samples, m_samples, acceptance_rate])\n",
    "\n",
    "# Some initial results\n",
    "print('acceptance_rate:', acceptance_rate_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3miTtcXWEck"
   },
   "source": [
    "### Plotting Results\n",
    "\n",
    "If everything has gone according to plan, at this point we will see a acceptance rate of the sampler of around 60%. Pretty good for our first bayesian hierarchical crack propagation model. A key metric for the HMC sampler are the sampled chains themselves, which should look \"mixed\" . In this case, the sampler did a decent job as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "colab_type": "code",
    "id": "nsNL2U1DUVKf",
    "outputId": "ba6048b3-8995-4f60-f001-dd7497020a27"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.style.use('fivethirtyeight')\n",
    "# plotting the mcmc chains\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(np.arange(samples), logC_samples_, color=TFColor[3])\n",
    "plt.title('C samples',fontsize=20)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(np.arange(samples), m_samples_, color=TFColor[0])\n",
    "plt.title('m samples',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTDqPD_GWMan"
   },
   "source": [
    "\n",
    "If we collect our sample and rescale them to the original space, we can get some summary statistics on the posterior estimates of the calibrated parameters $\\log(C)$ and $m$ and take a look at the distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "qFCvl9QdUYnD",
    "outputId": "9a727ecf-d5ab-4048-da85-01d58534a986"
   },
   "outputs": [],
   "source": [
    "# Converting to proper scale\n",
    "logC_samples_scale = logC_samples_ * np.sqrt(prio_par_logC[1]) + prio_par_logC[0]\n",
    "m_samples_scale = m_samples_ * np.sqrt(prio_par_m[1]) + prio_par_m[0]\n",
    "df = pd.DataFrame(np.concatenate([m_samples_scale[:,None], logC_samples_scale[:,None]], axis = 1), columns = ['m', 'logC'])\n",
    "\n",
    "ax = pd.plotting.scatter_matrix(df,figsize=(7.2,7.2))\n",
    "\n",
    "for axi in ax:\n",
    "    axi[0].tick_params(labelsize=16)\n",
    "    axi[1].tick_params(labelsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0woLluP3WQ2d"
   },
   "source": [
    "It is interesting to note that although we started off with two independent Gaussian distributions for $C$ and $m$, the posterior distributions are highly correlated. This is because, the solution space dictates that for high values for m, the only physically meaningful results lie at small values of C and vice-versa. If one were to have used any number of deterministic optimization techniques to find the \"best fit\" for $C$ and $m$ that fits this dataset, we could end up in any value that lies on the straight line depending on our starting point and constraints. Performing a probabilsitic optimization (a.k.a. Bayesian calibration) provides us with a global view of all possible solutions that can explain the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "NyMo_NqWE9zY",
    "outputId": "59d67d77-110f-4280-f184-533daa45b022"
   },
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.05, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZ7YX1YalMGJ"
   },
   "source": [
    "### Sampling the Posterior for Prognostic\n",
    "\n",
    "And now for the final act, we shall define a posterior function for our probabilistic crack propagation model, in order to finaly make the prognostic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dd_mhMjmUjSY"
   },
   "outputs": [],
   "source": [
    "def posterior(logC_samples, m_samples, time):\n",
    "    n_s = len(logC_samples)\n",
    "    n_inputs = len(time)\n",
    "\n",
    "    # Some Constants\n",
    "    dsig = 75.\n",
    "    B = tf.constant(dsig * np.pi**0.5, tf.float32)\n",
    "\n",
    "    # Crack Propagation model - compute in the log space\n",
    "\n",
    "    y_model =(\n",
    "        time[:,None]  *\n",
    "        tf.exp(logC_samples[None,:])*\n",
    "        (1-m_samples[None,:]/2.0) *B**m_samples[None,:] +y0** (1-m_samples[None,:]/2.0))**(2. / (2. - m_samples[None,:]))\n",
    "    noise = tfd.Normal(loc=0., scale=0.001)\n",
    "    samples = y_model + noise.sample(n_s)[tf.newaxis,:]\n",
    "    # The evaluate() function, defined at the top of this notebook, runs `sess.run()` \n",
    "    # in graph mode and allows code to be executed eagerly when Eager mode is enabled\n",
    "    samples_ = evaluate(samples)\n",
    "\n",
    "    return samples_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XQpoDFlPFFNi",
    "outputId": "91fdb0c9-dbe2-412f-8a37-14cecce5317e"
   },
   "outputs": [],
   "source": [
    "# Predict for a range of cycles\n",
    "time = np.arange(0, 3000, 100)\n",
    "y_samples = posterior(logC_samples_scale, m_samples_scale, time)\n",
    "print(y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "colab_type": "code",
    "id": "qcpj3jtoFIHp",
    "outputId": "9ce2f6d9-83d0-4ecc-e05c-f2810b0f5cfe"
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'Dejavu Sans','size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "#lower_per = np.percentile(y_samples,2.5, axis = 1)\n",
    "#upper_per = np.percentile(y_samples,97.5, axis = 1)\n",
    "lower_per = np.nanpercentile(y_samples, 2.5, axis = 1)\n",
    "upper_per = np.nanpercentile(y_samples, 97.5, axis = 1)\n",
    "\n",
    "plt.figure(figsize =(20,10))\n",
    "\n",
    "for samps in range(y_samples.shape[1]):\n",
    "    if samps % 250 == 0:\n",
    "        plt.plot(time, y_samples[:,samps],color=TFColor[3], alpha = 0.05)\n",
    "\n",
    "plt.plot(time, y_samples[:,-1],color=TFColor[3], label='Sample',alpha = 0.5)\n",
    "plt.plot(time, np.nanmedian(y_samples,axis=1), TFColor[0], label = 'Median',linewidth=2)\n",
    "plt.plot(t_,y_,'X', color='black', label = 'Data', markersize=12)\n",
    "plt.xlabel('Cycles')\n",
    "plt.ylabel('Crack size ')\n",
    "plt.hlines(0.05, np.min(time), np.max(time), linestyles = '--', label = 'threshold')\n",
    "plt.ylim([-0., 0.15])\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "npGlrZL5Uq-t"
   },
   "source": [
    "The predicted mean with the 95% uncertainty bounds of crack length using the hybrid-physics probabilistic model is shown below. Clearly, the model captures both the mean behavior as well as provides an estimate of uncertainty (of the model prediction) for every time point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1xuPYceU1Mx"
   },
   "source": [
    "## Next steps\n",
    "We have obviously chosen the example carefully to provide a gentle introduction to probabilistic models. There are several challenges in applying probabilistic models to real-world applications. Even in a simple problem like the one shown here, the solution becomes difficult if we relax the assumption that the priors are Gaussian. The more inquisitive reader can try using uniform priors to see the dramatic change in the predictive capability of the model. We will address some of the more practical challenges and their mitigation in the next blogs.\n",
    "\n",
    "This is the first of a series of blogs aimed at expanding the use of Probabilistic and Deep Learning techniques for industrial applications with TensorFlow Probability. We would love to hear about your applications and look forward to seeing these methods used in unique ways. Stay tuned to this blog feed for more updates and examples on anomaly detection, missing data estimation and forecasting with variational inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRwoxv8hUiJw"
   },
   "source": [
    "### Acknowledgments\n",
    "\n",
    "This blog is a result of the hard work and deep collaboration of several teams in Google and BHGE. We are particularly grateful to Josh Dillon, Michael Shwe, Scott Fitzharris, Alex Walker, Christian Hillaire, Arun Subramaniyan, and Fabio Nonato for their many edits, results, code snippets and most importantly enthusiastic support."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " Industrial_AI_BHGE_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
